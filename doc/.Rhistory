library(tidytext)
library(tidyverse)
library(DT)
#install.packages("tm")
#install.packages("data.table")
install.packages("DT")
library(tm)
library(data.table)
library(tidytext)
library(tidyverse)
library(DT)
install.packages("DT")
#install.packages("tm")
#install.packages("data.table")
install.packages("DT")
# load lyrics data
load('../data/lyrics.RData')
# load lyrics data
load('../data/lyrics.RData')
# function for removimg leading and trailing whitespace from character strings
leadingWhitespace <- content_transformer(function(x) str_trim(x, side = "both"))
# remove stop words
data("stop_words")
word <- c("lot", "today", "months", "month", "wanna", "wouldnt", "wasnt", "ha", "na", "ooh", "da",
"gonna", "im", "dont", "aint", "wont", "yeah", "la", "oi", "nigga", "fuck",
"hey", "year", "years", "last", "past", "feel")
stop_words <- c(stop_words$word, word)
# clean the data and make a corpus
corpus <- VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(removeWords, stop_words)%>%
tm_map(removeNumbers)%>%
tm_map(stripWhitespace)%>%
tm_map(leadingWhitespace)
corpus <- VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(removeWords, stop_words)%>%
tm_map(removeNumbers)%>%
tm_map(stripWhitespace)%>%
tm_map(leadingWhitespace)
stop_words
stop_words$word
stop_words
removePunctuation
removeWords
removeNumbers
stripWhitespace
leadingWhitespace
stripWhitespace
removeWords
removePunctuation
content_transformer
leadingWhitespace
# function for removimg leading and trailing whitespace from character strings
leadingWhitespace <- content_transformer(function(x) str_trim(x, side = "both"))
# remove stop words
data("stop_words")
word <- c("lot", "today", "months", "month", "wanna", "wouldnt", "wasnt", "ha", "na", "ooh", "da",
"gonna", "im", "dont", "aint", "wont", "yeah", "la", "oi", "nigga", "fuck",
"hey", "year", "years", "last", "past", "feel")
stop_words <- c(stop_words$word, word)
# clean the data and make a corpus
corpus <- VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(removeWords, stop_words)%>%
tm_map(removeNumbers)%>%
tm_map(stripWhitespace)%>%
tm_map(leadingWhitespace)
VCorpus(VectorSource(dt_lyrics$lyrics))
VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))
VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation
VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)
VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))
VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(removeWords, stop_words)
removeWords
character(0)
stop_words
removeWords
VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(removeWords, stop_words)
folder.path="../data/inaugurals/"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
ff.all<-Corpus(DirSource(folder.path))
ff.all<-tm_map(ff.all, stripWhitespace)
ff.all<-tm_map(ff.all, content_transformer(tolower)) #content transformer for defining your own function
ff.all<-tm_map(ff.all, removeWords, stopwords("english"))
ff.all<-tm_map(ff.all, removeWords, character(0))
ff.all<-tm_map(ff.all, removePunctuation)
tdm.all<-TermDocumentMatrix(ff.all) #count for number of times a word appears
tdm.tidy=tidy(tdm.all)
tdm.overall=summarise(group_by(tdm.tidy, term), sum(count))
tdm.overall
wordcloud(tdm.overall$term, tdm.overall$`sum(count)`,
scale=c(5,0.5),
max.words=100,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
use.r.layout=T,
random.color=FALSE,
colors=brewer.pal(9,"Blues"))
library(tidytext)
wordcloud(tdm.overall$term, tdm.overall$`sum(count)`,
scale=c(5,0.5),
max.words=100,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
use.r.layout=T,
random.color=FALSE,
colors=brewer.pal(9,"Blues"))
install.packages("wordcloud")
library("wordcloud")
wordcloud(tdm.overall$term, tdm.overall$`sum(count)`,
scale=c(5,0.5),
max.words=100,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
use.r.layout=T,
random.color=FALSE,
colors=brewer.pal(9,"Blues"))
dtm <- DocumentTermMatrix(ff.all,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
ff.dtm=tidy(dtm)
ff.dtm
library(shiny)
shinyApp(
ui = fluidPage(
fluidRow(style = "padding-bottom: 20px;",
column(4, selectInput('speech1', 'Speech 1',
speeches,
selected=speeches[5])),
column(4, selectInput('speech2', 'Speech 2', speeches,
selected=speeches[9])),
column(4, sliderInput('nwords', 'Number of words', 3,
min = 20, max = 200, value=100, step = 20))
),
fluidRow(
plotOutput('wordclouds', height = "400px")
)
),
server = function(input, output, session) {
# Combine the selected variables into a new data frame
selectedData <- reactive({
list(dtm.term1=ff.dtm$term[ff.dtm$document==as.character(input$speech1)],
dtm.count1=ff.dtm$count[ff.dtm$document==as.character(input$speech1)],
dtm.term2=ff.dtm$term[ff.dtm$document==as.character(input$speech2)],
dtm.count2=ff.dtm$count[ff.dtm$document==as.character(input$speech2)])
})
output$wordclouds <- renderPlot(height = 400, {
par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
wordcloud(selectedData()$dtm.term1,
selectedData()$dtm.count1,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(10,"Blues"),
main=input$speech1)
wordcloud(selectedData()$dtm.term2,
selectedData()$dtm.count2,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(10,"Blues"),
main=input$speech2)
})
},
options = list(height = 600)
)
head(dt_lyrics)
corpus <- VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(removeWords, stop_words)%>%
tm_map(removeNumbers)%>%
tm_map(stripWhitespace)%>%
tm_map(leadingWhitespace)
corpus <- VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(removeWords, stop_words)%>%
tm_map(removeNumbers)%>%
tm_map(stripWhitespace)%>%
tm_map(leadingWhitespace)
# clean the data and make a corpus
lyr <-  VCorpus(VectorSource(dt_lyrics$lyrics))
lyr
corpus <- tm_map(lyr, stripWhitespace)
corpus
corpus <- tm_map(lyr, content_transformer(tolower))
corpus <- tm_map(lyr, removeWords, stop_words)
corpus <- tm_map(lyr, removeWords, stop_words)
corpus <- tm_map(lyr, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, stop_words)
corpus <- tm_map(lyr, removeWords, character(0))
corpus <- tm_map(lyr, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, character(0))
#install.packages("tm")
#install.packages("data.table")
install.packages("DT")
library(tm)
library(data.table)
library(tidytext)
library(tidyverse)
library(DT)
# load lyrics data
load('../data/lyrics.RData')
head(dt_lyrics)
# function for removimg leading and trailing whitespace from character strings
leadingWhitespace <- content_transformer(function(x) str_trim(x, side = "both"))
# remove stop words
data("stop_words")
word <- c("lot", "today", "months", "month", "wanna", "wouldnt", "wasnt", "ha", "na", "ooh", "da",
"gonna", "im", "dont", "aint", "wont", "yeah", "la", "oi", "nigga", "fuck",
"hey", "year", "years", "last", "past", "feel")
stop_words <- c(stop_words$word, word)
stop_words <- c(stop_words$word, word)
# remove stop words
data("stop_words")
word <- c("lot", "today", "months", "month", "wanna", "wouldnt", "wasnt", "ha", "na", "ooh", "da",
"gonna", "im", "dont", "aint", "wont", "yeah", "la", "oi", "nigga", "fuck",
"hey", "year", "years", "last", "past", "feel")
stop_words
stop_words$word
stop_words <- c(stop_words$word, word)
corpus <- VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(removeWords, stop_words)%>%
tm_map(removeNumbers)%>%
tm_map(stripWhitespace)%>%
tm_map(leadingWhitespace)
stop_words
corpus <- VCorpus(VectorSource(dt_lyrics$lyrics))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeWords, character(0))%>%
tm_map(removeWords, stop_words)%>%
tm_map(removeNumbers)%>%
tm_map(stripWhitespace)%>%
tm_map(leadingWhitespace)
lyr <-  VCorpus(VectorSource(dt_lyrics$lyrics))
lower <- tm_map(lyr, content_transformer(tolower))
punc <- tm_map(lower, removePunctuation)
rmwords <- tm_map(punc, removeWords, character(0))
stop <- tm_map(rmwords, removeWords, stop_words)
typeof(stop_words)
typeof(word)
stop_words[1]
stop_words[20]
rmwords
stop
stop <- tm_map(rmwords, removeWords, stop_words)
num <- tm_map(stop, removeNumbers)
white <- tm_map(num, stripWhitespace)
corpus <- tm_map(white, leadingWhitespace)
stemmed <- tm_map(corpus, stemDocument) %>%
tidy() %>%
select(text)
dict <- tidy(corpus) %>%
select(text) %>%
unnest_tokens(dictionary, text)
completed <- stemmed %>%
mutate(id = row_number()) %>%
unnest_tokens(stems, text) %>%
bind_cols(dict)
completed <- completed %>%
group_by(stems) %>%
count(dictionary) %>%
mutate(word = dictionary[which.max(n)]) %>%
ungroup() %>%
select(stems, word) %>%
distinct() %>%
right_join(completed) %>%
select(-stems)
completed <- completed %>%
group_by(id) %>%
summarise(stemmedwords= str_c(word, collapse = " ")) %>%
ungroup()
dt_lyrics <- dt_lyrics %>%
mutate(id = row_number()) %>%
inner_join(completed)
save(dt_lyrics, file="../output/processed_lyrics.RData")
load("/Users/jasminflack/Desktop/Applied Data Science/Project 1/Spring2020-Project1-JasminFlack/output/processed_lyrics.RData")
library(tidyverse)
library(tidytext)
library(plotly)
install.packages("plotly")
#install.packages("plotly")
library(tidyverse)
library(tidytext)
library(plotly)
library(DT)
library(tm)
library(data.table)
library(scales)
library(wordcloud2)
#install.packages("plotly")
install.packages("wordcloud2")
#install.packages("plotly")
#install.packages("wordcloud2")
library(tidyverse)
library(tidytext)
library(plotly)
library(DT)
library(tm)
library(data.table)
library(scales)
library(wordcloud2)
library(gridExtra)
#install.packages("plotly")
#install.packages("wordcloud2")
install.packages("gridExtra")
#install.packages("plotly")
#install.packages("wordcloud2")
#install.packages("gridExtra")
library(tidyverse)
library(tidytext)
library(plotly)
library(DT)
library(tm)
library(data.table)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
#install.packages("plotly")
#install.packages("wordcloud2")
#install.packages("gridExtra")
install.packages("ngram")
library(tidyverse)
library(tidytext)
library(plotly)
library(DT)
library(tm)
library(data.table)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny)
# load lyrics data
load('../output/processed_lyrics.RData')
# load artist information
dt_artist <- fread('../data/artists.csv')
lyrics_list <- c("Folk", "R&B", "Electronic", "Jazz", "Indie", "Country", "Rock", "Metal", "Pop", "Hip-Hop", "Other")
time_list <- c("1970s", "1980s", "1990s", "2000s", "2010s")
corpus <- VCorpus(VectorSource(dt_lyrics$stemmedwords))
word_tibble <- tidy(corpus) %>%
select(text) %>%
mutate(id = row_number()) %>%
unnest_tokens(word, text)
# Define UI for app that draws a histogram ----
ui <- navbarPage(strong("Lyrics Analysis"),
tabPanel("Overview",
titlePanel("Most frequent words"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
sliderInput(inputId = "nwords1",
label = "Number of terms in the first word cloud:",
min = 5, max = 100, value = 50),
selectInput('genre1', 'Genre of the first word cloud',
lyrics_list, selected='Folk')
),
# Main panel for displaying outputs ----
mainPanel(
wordcloud2Output(outputId = "WC1", height = "300")
)
),
hr(),
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
sliderInput(inputId = "nwords2",
label = "Number of terms in the second word cloud:",
min = 5, max = 100, value = 50),
selectInput('genre2', 'Genre of the second word cloud',
lyrics_list, selected='Metal')
),
# Main panel for displaying outputs ----
mainPanel(
wordcloud2Output(outputId = "WC2", height = "300")
)
)
),
tabPanel("Time Variation",
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
selectInput('decade1', 'Selected decade for the first plot:',
time_list, selected='1970s'),
selectInput('decade2', 'Selected decade for the second plot:',
time_list, selected='1980s'),
numericInput(inputId = "topBigrams",
label = "Number of top pairs to view:",
min = 1,
max = 20,
value = 10)
),
# Main panel for displaying outputs ----
mainPanel(
fluidRow(
column(5,
plotlyOutput("bigram1")),
column(5,
plotlyOutput("bigram2"))
)
)
)
),
tabPanel("Data",
DT::dataTableOutput("table"))
)
server <- function(input, output) {
output$WC1 <- renderWordcloud2({
count(filter(word_tibble, id %in% which(dt_lyrics$genre == input$genre1)), word, sort = TRUE) %>%
slice(1:input$nwords1) %>%
wordcloud2(size=0.6, rotateRatio=0.2)
})
output$WC2 <- renderWordcloud2({
count(filter(word_tibble, id %in% which(dt_lyrics$genre == input$genre2)), word, sort = TRUE) %>%
slice(1:input$nwords2) %>%
wordcloud2(size=0.6, rotateRatio=0.2)
})
output$bigram1 <- renderPlotly({
year_start <- as.integer(substr(input$decade1, 1, 4))
dt_sub <- filter(dt_lyrics, year>=year_start) %>%
filter(year<(year_start+10))
lyric_bigrams <- dt_sub %>%
unnest_tokens(bigram, stemmedwords, token = "ngrams", n = 2)
bigram_counts <- lyric_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
combined_words <- apply(bigram_counts[c(1, 2)], 1, paste , collapse = " " )[1:input$topBigrams]
x_names <- factor(combined_words, levels = rev(combined_words))
plot_ly(
x = bigram_counts$n[1:input$topBigrams],
y = x_names,
name = "Bigram",
type = "bar",
orientation = 'h'
)
})
output$bigram2 <- renderPlotly({
year_start <- as.integer(substr(input$decade2, 1, 4))
dt_sub <- filter(dt_lyrics, year>=year_start) %>%
filter(year<(year_start+10))
lyric_bigrams <- dt_sub %>%
unnest_tokens(bigram, stemmedwords, token = "ngrams", n = 2)
bigram_counts <- lyric_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
combined_words <- apply(bigram_counts[c(1, 2)], 1, paste , collapse = " " )[1:input$topBigrams]
x_names <- factor(combined_words, levels = rev(combined_words))
plot_ly(
x = bigram_counts$n[1:input$topBigrams],
y = x_names,
name = "Bigram",
type = "bar",
orientation = 'h'
)
})
output$table <- DT::renderDataTable({
DT::datatable(dt_lyrics)
})
}
shinyApp(ui, server)
install.packages("rlang")
install.packages("rlang")
shinyApp(ui, server)
